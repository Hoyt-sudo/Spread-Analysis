{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a904011f-7d36-40c2-b3e3-49e682e4d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from decimal import Decimal, ROUND_HALF_UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da2a131-e81b-4910-a312-a75d22ec70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base_path is the folder contains the StoneX and other brokers' folder.\n",
    "base_path = \"20240527_test/20240527\"\n",
    "# The products need to be dealt with\n",
    "products = ['CHINAA50', 'COPPER', 'EURUSD', 'GBPUSD', 'GER40', 'HK50', 'NAS100', 'SPX500', 'US_OIL', 'US30', 'USDJPY', 'XAGUSD', 'XAUUSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824e1c5-48a3-47d2-9cac-d4c8ede009e5",
   "metadata": {},
   "source": [
    "## Files Rename\n",
    "Considering the name from different brokers are always the same, so every time we get the new data, we can use this part of code to automaticly rename the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d0f1c6b-ad30-4979-9745-ec82568ae8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240527_test/20240527\\AvA Trade Successfully Renamed\n",
      "20240527_test/20240527\\FXCM Successfully Renamed\n",
      "20240527_test/20240527\\FXTM Successfully Renamed\n",
      "20240527_test/20240527\\IC Markets Successfully Renamed\n",
      "20240527_test/20240527\\KVB Successfully Renamed\n",
      "20240527_test/20240527\\StoneX Successfully Renamed\n",
      "20240527_test/20240527\\XM Successfully Renamed\n"
     ]
    }
   ],
   "source": [
    "# Define how to rename\n",
    "rename_mapping = {\n",
    "    # CHINAA50\n",
    "    'CHINA_A50': 'CHINAA50',\n",
    "    'CHN50': 'CHINAA50',\n",
    "    'CN50': 'CHINAA50',\n",
    "    'CHINA50': 'CHINAA50',\n",
    "    'ChinaA50.p': 'CHINAA50',\n",
    "    'China50Cash': 'CHINAA50',\n",
    "\n",
    "    # COPPER\n",
    "    'Copper': 'COPPER',\n",
    "\n",
    "    # US_OIL\n",
    "    'CrudeOIL': 'US_OIL',\n",
    "    'Crude': 'US_OIL',\n",
    "    'USOil': 'US_OIL',\n",
    "    'XTIUSD': 'US_OIL',\n",
    "    'USOIL.p': 'US_OIL',\n",
    "\n",
    "    # EURUSD\n",
    "    'EURUSD': 'EURUSD',\n",
    "    'EURUSD.p': 'EURUSD',\n",
    "    'EURUSDmicro': 'EURUSD',\n",
    "\n",
    "    # GBPUSD\n",
    "    'GBPUSD': 'GBPUSD',\n",
    "    'GBPUSD.p': 'GBPUSD',\n",
    "    'GBPUSDmicro': 'GBPUSD',\n",
    "\n",
    "    # GER40\n",
    "    'GERMANY_40': 'GER40',\n",
    "    'GER30': 'GER40',\n",
    "    'DE40': 'GER40',\n",
    "    'DAX.p': 'GER40',\n",
    "    'GER40Cash': 'GER40',\n",
    "\n",
    "    # XAUUSD\n",
    "    'GOLD': 'XAUUSD',\n",
    "    'GOLD_micro': 'XAUUSD',\n",
    "    'XAUUSD.p': 'XAUUSD',\n",
    "\n",
    "    # HK50\n",
    "    'HK_50': 'HK50',\n",
    "    'HKG33': 'HK50',\n",
    "    'HSI.p': 'HK50',\n",
    "    'HK50Cash': 'HK50',\n",
    "\n",
    "    # XAGUSD\n",
    "    'SILVER': 'XAGUSD',\n",
    "    'SILVER_micro': 'XAGUSD',\n",
    "    'XAGUSD.p': 'XAGUSD',\n",
    "\n",
    "    # US30\n",
    "    'US_30': 'US30',\n",
    "    'DOW.p': 'US30',\n",
    "    'US30Cash': 'US30',\n",
    "\n",
    "    # SPX500\n",
    "    'US_500': 'SPX500',\n",
    "    'US500': 'SPX500',\n",
    "    'SPX500.p': 'SPX500',\n",
    "    'US500Cash': 'SPX500',\n",
    "\n",
    "    # NAS100\n",
    "    'US_TECH100': 'NAS100',\n",
    "    'USTEC': 'NAS100',\n",
    "    'NAS100.p': 'NAS100',\n",
    "    'US100Cash': 'NAS100',\n",
    "\n",
    "    # USDJPY\n",
    "    'USDJPY': 'USDJPY',\n",
    "    'USDJPY.p': 'USDJPY',\n",
    "    'USDJPYmicro': 'USDJPY',\n",
    "\n",
    "    # Others\n",
    "    'USOilSpot': 'USOilSpot',\n",
    "    'WTI_N4': 'WTI_N4',\n",
    "    'CHINA300.p': 'CHINA300.p',\n",
    "    'HGCOP-JUL24': 'HGCOP-JUL24',\n",
    "    'OIL-JUL24': 'OIL-JUL24',\n",
    "}\n",
    "\n",
    "# Rename all the folders\n",
    "for folder_name in os.listdir(base_path):\n",
    "    folder_path = os.path.join(base_path, folder_name)\n",
    "    if os.path.isdir(folder_path): \n",
    "        for file_name in os.listdir(folder_path):\n",
    "            old_file_path = os.path.join(folder_path, file_name)\n",
    "            new_file_name = rename_mapping.get(file_name, file_name)  \n",
    "            new_file_path = os.path.join(folder_path, new_file_name)\n",
    "            \n",
    "            os.rename(old_file_path, new_file_path)\n",
    "        print(f\"{folder_path} Successfully Renamed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e0df7-f8ca-46e6-82ad-6c5063034930",
   "metadata": {},
   "source": [
    "## Deal with the bid and ask's order of magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edbd0056-f8cd-49f3-87fd-b37b8cbf4259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240527_test/20240527\\AvA Trade\\CHINAA50\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - CHINAA50: 1\n",
      "20240527_test/20240527\\AvA Trade\\COPPER\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - COPPER: 0.01\n",
      "20240527_test/20240527\\AvA Trade\\EURUSD\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - EURUSD: 1\n",
      "20240527_test/20240527\\AvA Trade\\GBPUSD\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - GBPUSD: 1\n",
      "20240527_test/20240527\\AvA Trade\\GER40\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - GER40: 1\n",
      "20240527_test/20240527\\AvA Trade\\HK50\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - HK50: 1\n",
      "20240527_test/20240527\\AvA Trade\\NAS100\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - NAS100: 1\n",
      "20240527_test/20240527\\AvA Trade\\SPX500\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - SPX500: 1\n",
      "20240527_test/20240527\\AvA Trade\\US_OIL\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - US_OIL: 1\n",
      "20240527_test/20240527\\AvA Trade\\US30\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - US30: 1\n",
      "20240527_test/20240527\\AvA Trade\\USDJPY\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - USDJPY: 1\n",
      "20240527_test/20240527\\AvA Trade\\XAGUSD\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - XAGUSD: 1\n",
      "20240527_test/20240527\\AvA Trade\\XAUUSD\\05192024.CSV\n",
      "Calculated ratio for AvA Trade - XAUUSD: 1\n",
      "Processed all files in brand folder: AvA Trade\n",
      "20240527_test/20240527\\FXCM\\CHINAA50\\05192024.CSV\n",
      "Calculated ratio for FXCM - CHINAA50: 1\n",
      "20240527_test/20240527\\FXCM\\COPPER\\05192024.CSV\n",
      "Calculated ratio for FXCM - COPPER: 0.01\n",
      "20240527_test/20240527\\FXCM\\EURUSD\\05192024.CSV\n",
      "Calculated ratio for FXCM - EURUSD: 1\n",
      "20240527_test/20240527\\FXCM\\GBPUSD\\05192024.CSV\n",
      "Calculated ratio for FXCM - GBPUSD: 1\n",
      "20240527_test/20240527\\FXCM\\GER40\\05192024.CSV\n",
      "Calculated ratio for FXCM - GER40: 1\n",
      "20240527_test/20240527\\FXCM\\HK50\\05192024.CSV\n",
      "Calculated ratio for FXCM - HK50: 1\n",
      "20240527_test/20240527\\FXCM\\NAS100\\05192024.CSV\n",
      "Calculated ratio for FXCM - NAS100: 1\n",
      "20240527_test/20240527\\FXCM\\SPX500\\05192024.CSV\n",
      "Calculated ratio for FXCM - SPX500: 1\n",
      "20240527_test/20240527\\FXCM\\US_OIL\\05192024.CSV\n",
      "Calculated ratio for FXCM - US_OIL: 1\n",
      "20240527_test/20240527\\FXCM\\US30\\05192024.CSV\n",
      "Calculated ratio for FXCM - US30: 1\n",
      "20240527_test/20240527\\FXCM\\USDJPY\\05192024.CSV\n",
      "Calculated ratio for FXCM - USDJPY: 1\n",
      "20240527_test/20240527\\FXCM\\XAGUSD\\05192024.CSV\n",
      "Calculated ratio for FXCM - XAGUSD: 1\n",
      "20240527_test/20240527\\FXCM\\XAUUSD\\05192024.CSV\n",
      "Calculated ratio for FXCM - XAUUSD: 1\n",
      "Processed all files in brand folder: FXCM\n",
      "20240527_test/20240527\\FXTM\\CHINAA50\\05192024.CSV\n",
      "Calculated ratio for FXTM - CHINAA50: 1\n",
      "20240527_test/20240527\\FXTM\\EURUSD\\05192024.CSV\n",
      "Calculated ratio for FXTM - EURUSD: 1\n",
      "20240527_test/20240527\\FXTM\\GBPUSD\\05192024.CSV\n",
      "Calculated ratio for FXTM - GBPUSD: 1\n",
      "20240527_test/20240527\\FXTM\\GER40\\05192024.CSV\n",
      "Calculated ratio for FXTM - GER40: 1\n",
      "20240527_test/20240527\\FXTM\\HK50\\05192024.CSV\n",
      "Calculated ratio for FXTM - HK50: 1\n",
      "20240527_test/20240527\\FXTM\\NAS100\\05192024.CSV\n",
      "Calculated ratio for FXTM - NAS100: 1\n",
      "20240527_test/20240527\\FXTM\\SPX500\\05192024.CSV\n",
      "Calculated ratio for FXTM - SPX500: 1\n",
      "20240527_test/20240527\\FXTM\\US_OIL\\05192024.CSV\n",
      "Calculated ratio for FXTM - US_OIL: 1\n",
      "20240527_test/20240527\\FXTM\\US30\\05192024.CSV\n",
      "Calculated ratio for FXTM - US30: 1\n",
      "20240527_test/20240527\\FXTM\\USDJPY\\05192024.CSV\n",
      "Calculated ratio for FXTM - USDJPY: 1\n",
      "20240527_test/20240527\\FXTM\\XAGUSD\\05192024.CSV\n",
      "Calculated ratio for FXTM - XAGUSD: 1\n",
      "20240527_test/20240527\\FXTM\\XAUUSD\\05192024.CSV\n",
      "Calculated ratio for FXTM - XAUUSD: 1\n",
      "Processed all files in brand folder: FXTM\n",
      "20240527_test/20240527\\IC Markets\\CHINAA50\\05192024.CSV\n",
      "Calculated ratio for IC Markets - CHINAA50: 1\n",
      "20240527_test/20240527\\IC Markets\\EURUSD\\05192024.CSV\n",
      "Calculated ratio for IC Markets - EURUSD: 1\n",
      "20240527_test/20240527\\IC Markets\\GBPUSD\\05192024.CSV\n",
      "Calculated ratio for IC Markets - GBPUSD: 1\n",
      "20240527_test/20240527\\IC Markets\\GER40\\05192024.CSV\n",
      "Calculated ratio for IC Markets - GER40: 1\n",
      "20240527_test/20240527\\IC Markets\\HK50\\05192024.CSV\n",
      "Calculated ratio for IC Markets - HK50: 1\n",
      "20240527_test/20240527\\IC Markets\\NAS100\\05192024.CSV\n",
      "Calculated ratio for IC Markets - NAS100: 1\n",
      "20240527_test/20240527\\IC Markets\\SPX500\\05192024.CSV\n",
      "Calculated ratio for IC Markets - SPX500: 1\n",
      "20240527_test/20240527\\IC Markets\\US_OIL\\05192024.CSV\n",
      "Calculated ratio for IC Markets - US_OIL: 1\n",
      "20240527_test/20240527\\IC Markets\\US30\\05192024.CSV\n",
      "Calculated ratio for IC Markets - US30: 1\n",
      "20240527_test/20240527\\IC Markets\\USDJPY\\05192024.CSV\n",
      "Calculated ratio for IC Markets - USDJPY: 1\n",
      "20240527_test/20240527\\IC Markets\\XAGUSD\\05192024.CSV\n",
      "Calculated ratio for IC Markets - XAGUSD: 1\n",
      "20240527_test/20240527\\IC Markets\\XAUUSD\\05192024.CSV\n",
      "Calculated ratio for IC Markets - XAUUSD: 1\n",
      "Processed all files in brand folder: IC Markets\n",
      "20240527_test/20240527\\KVB\\CHINAA50\\05192024.CSV\n",
      "Calculated ratio for KVB - CHINAA50: 1\n",
      "20240527_test/20240527\\KVB\\EURUSD\\05192024.CSV\n",
      "Calculated ratio for KVB - EURUSD: 1\n",
      "20240527_test/20240527\\KVB\\GBPUSD\\05192024.CSV\n",
      "Calculated ratio for KVB - GBPUSD: 1\n",
      "20240527_test/20240527\\KVB\\GER40\\05192024.CSV\n",
      "Calculated ratio for KVB - GER40: 1\n",
      "20240527_test/20240527\\KVB\\HK50\\05192024.CSV\n",
      "Calculated ratio for KVB - HK50: 1\n",
      "20240527_test/20240527\\KVB\\NAS100\\05192024.CSV\n",
      "Calculated ratio for KVB - NAS100: 1\n",
      "20240527_test/20240527\\KVB\\SPX500\\05192024.CSV\n",
      "Calculated ratio for KVB - SPX500: 1\n",
      "20240527_test/20240527\\KVB\\US_OIL\\05192024.CSV\n",
      "Calculated ratio for KVB - US_OIL: 1\n",
      "20240527_test/20240527\\KVB\\US30\\05192024.CSV\n",
      "Calculated ratio for KVB - US30: 1\n",
      "20240527_test/20240527\\KVB\\USDJPY\\05192024.CSV\n",
      "Calculated ratio for KVB - USDJPY: 1\n",
      "20240527_test/20240527\\KVB\\XAGUSD\\05192024.CSV\n",
      "Calculated ratio for KVB - XAGUSD: 1\n",
      "20240527_test/20240527\\KVB\\XAUUSD\\05192024.CSV\n",
      "Calculated ratio for KVB - XAUUSD: 1\n",
      "Processed all files in brand folder: KVB\n",
      "20240527_test/20240527\\XM\\CHINAA50\\05192024.CSV\n",
      "Calculated ratio for XM - CHINAA50: 1\n",
      "20240527_test/20240527\\XM\\EURUSD\\05192024.CSV\n",
      "Calculated ratio for XM - EURUSD: 1\n",
      "20240527_test/20240527\\XM\\GBPUSD\\05192024.CSV\n",
      "Calculated ratio for XM - GBPUSD: 1\n",
      "20240527_test/20240527\\XM\\GER40\\05192024.CSV\n",
      "Calculated ratio for XM - GER40: 1\n",
      "20240527_test/20240527\\XM\\HK50\\05192024.CSV\n",
      "Calculated ratio for XM - HK50: 1\n",
      "20240527_test/20240527\\XM\\NAS100\\05192024.CSV\n",
      "Calculated ratio for XM - NAS100: 1\n",
      "20240527_test/20240527\\XM\\SPX500\\05192024.CSV\n",
      "Calculated ratio for XM - SPX500: 1\n",
      "20240527_test/20240527\\XM\\US30\\05192024.CSV\n",
      "Calculated ratio for XM - US30: 1\n",
      "20240527_test/20240527\\XM\\USDJPY\\05192024.CSV\n",
      "Calculated ratio for XM - USDJPY: 1\n",
      "20240527_test/20240527\\XM\\XAGUSD\\05192024.CSV\n",
      "Calculated ratio for XM - XAGUSD: 1\n",
      "20240527_test/20240527\\XM\\XAUUSD\\05192024.CSV\n",
      "Calculated ratio for XM - XAUUSD: 1\n",
      "Processed all files in brand folder: XM\n",
      "Processed all files\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the bid ratios for each product in other brands\n",
    "bid_ratios = {}\n",
    "\n",
    "# Function to round the ratio to the nearest 100, 10, 1, 0.1, etc.\n",
    "def round_ratio(value):\n",
    "    if value>=500:\n",
    "        return 1000\n",
    "    elif value >= 50:\n",
    "        return 100\n",
    "    elif value >= 5:\n",
    "        return 10\n",
    "    elif value >= 0.5:\n",
    "        return 1\n",
    "    elif value >= 0.05:\n",
    "        return 0.1\n",
    "    elif value >= 0.005:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "# Process StoneX folder first to extract the baseline bid for each product\n",
    "stonex_folder = os.path.join(base_path, 'StoneX')\n",
    "stonex_first_bids = {}\n",
    "\n",
    "# Extract the first bid from StoneX for each product\n",
    "for product in products:\n",
    "    product_folder = os.path.join(stonex_folder, product)\n",
    "    \n",
    "    if os.path.isdir(product_folder):\n",
    "        # Loop through each CSV file in the product folder\n",
    "        for file_name in os.listdir(product_folder):\n",
    "            if file_name.endswith('.CSV'):\n",
    "                file_path = os.path.join(product_folder, file_name)\n",
    "                \n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Get the first Bid value\n",
    "                if 'Bid' in df.columns:\n",
    "                    stonex_first_bids[product] = df.loc[0, 'Bid']\n",
    "                    break  # Exit after the first file and first row for each product\n",
    "\n",
    "# Process other brands and calculate new Bid and Ask based on the ratio\n",
    "for brand_folder in os.listdir(base_path):\n",
    "    if brand_folder == 'StoneX':  # Skip StoneX as it has been processed\n",
    "        continue\n",
    "\n",
    "    brand_folder_path = os.path.join(base_path, brand_folder)\n",
    "\n",
    "    # Check if the path is a directory (brand folder)\n",
    "    if os.path.isdir(brand_folder_path):\n",
    "        # Process each product folder inside the brand folder\n",
    "        for product in products:\n",
    "            product_folder = os.path.join(brand_folder_path, product)\n",
    "\n",
    "            if os.path.isdir(product_folder):\n",
    "                # Calculate the ratio for the first file and first row in this product\n",
    "                for file_name in os.listdir(product_folder):\n",
    "                    if file_name.endswith('.CSV'):\n",
    "                        file_path = os.path.join(product_folder, file_name)\n",
    "                        # Read the CSV file into a DataFrame\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        \n",
    "                        if 'Bid' in df.columns and product in stonex_first_bids:\n",
    "                            # Get the first Bid value for this brand and product\n",
    "                            brand_first_bid = df.loc[0, 'Bid']\n",
    "                            \n",
    "                            # Calculate the ratio between this brand and StoneX\n",
    "                            bid_ratio = brand_first_bid / stonex_first_bids[product]\n",
    "                            # Round the ratio to the nearest 100, 10, 1, 0.1, etc.\n",
    "                            rounded_ratio = round_ratio(bid_ratio)\n",
    "                            \n",
    "                            # Store the rounded ratio for this product in this brand\n",
    "                            bid_ratios[(brand_folder, product)] = rounded_ratio\n",
    "                            \n",
    "                            print(f\"Calculated ratio for {brand_folder} - {product}: {rounded_ratio}\")\n",
    "                            break  # Exit after processing the first file for each product\n",
    "\n",
    "                # Apply the calculated ratio to adjust Bid and Ask for all files in this product\n",
    "                for file_name in os.listdir(product_folder):\n",
    "                    if file_name.endswith('.CSV'):\n",
    "                        file_path = os.path.join(product_folder, file_name)\n",
    "                        \n",
    "                        # Read the CSV file into a DataFrame\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        \n",
    "                        if 'Bid' in df.columns and 'Ask' in df.columns:\n",
    "                            # Get the rounded ratio for this brand and product\n",
    "                            ratio = bid_ratios.get((brand_folder, product), 1)\n",
    "                            \n",
    "                            # Apply the ratio to adjust Bid and Ask\n",
    "                            df['Bid'] = df['Bid'] / ratio\n",
    "                            df['Ask'] = df['Ask'] / ratio\n",
    "                            \n",
    "                            # Save the updated DataFrame back to the CSV\n",
    "                            df.to_csv(file_path, index=False)\n",
    "\n",
    "        # Print a message after processing all files in the brand folder\n",
    "        print(f\"Processed all files in brand folder: {brand_folder}\")\n",
    "\n",
    "print(f\"Processed all files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137724e6-4ec5-42eb-9167-7030feab1f53",
   "metadata": {},
   "source": [
    "## Recaculate new spread and replace old spread\n",
    "Different brands use different rules to caculate the spread. We can use python code to automaticly caculate all of the spread under the rule of StoneX, and replace the old spread in the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f5de284-5fdc-4bf8-b871-15cb862e1ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ratio for CHINAA50 in StoneX (rounded): 1.00\n",
      "First ratio for COPPER in StoneX (rounded): 100.00\n",
      "First ratio for EURUSD in StoneX (rounded): 100000.00\n",
      "First ratio for GBPUSD in StoneX (rounded): 100000.00\n",
      "First ratio for GER40 in StoneX (rounded): 10.00\n",
      "First ratio for HK50 in StoneX (rounded): 1.00\n",
      "First ratio for NAS100 in StoneX (rounded): 10.00\n",
      "First ratio for SPX500 in StoneX (rounded): 10.00\n",
      "First ratio for US_OIL in StoneX (rounded): 100.00\n",
      "First ratio for US30 in StoneX (rounded): 10.00\n",
      "First ratio for USDJPY in StoneX (rounded): 1000.00\n",
      "First ratio for XAGUSD in StoneX (rounded): 1000.00\n",
      "First ratio for XAUUSD in StoneX (rounded): 100.00\n",
      "Processed all files in brand folder: AvA Trade\n",
      "Processed all files in brand folder: FXCM\n",
      "Processed all files in brand folder: FXTM\n",
      "Processed all files in brand folder: IC Markets\n",
      "Processed all files in brand folder: KVB\n",
      "Processed all files in brand folder: XM\n",
      "Processed all files\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the spread ratio for each product in StoneX\n",
    "spread_ratios = {}\n",
    "\n",
    "# Function to dynamically round small values and avoid 0.00\n",
    "def round_decimal_dynamic(value, min_decimal_places=2, max_decimal_places=6):\n",
    "    \"\"\"Rounds the decimal value dynamically, ensuring it's not rounded to zero.\"\"\"\n",
    "    decimal_value = Decimal(value).quantize(Decimal('1.' + '0' * min_decimal_places), rounding=ROUND_HALF_UP)\n",
    "    \n",
    "    # If the value rounds to 0 with the minimum decimal places, increase precision\n",
    "    if decimal_value == Decimal('0.00'):\n",
    "        decimal_value = Decimal(value).quantize(Decimal('1.' + '0' * max_decimal_places), rounding=ROUND_HALF_UP)\n",
    "    \n",
    "    return decimal_value\n",
    "\n",
    "# Process StoneX folder first to extract the ratio from the first CSV file and its first row\n",
    "stonex_folder = os.path.join(base_path, 'StoneX')\n",
    "\n",
    "for product in products:\n",
    "    product_folder = os.path.join(stonex_folder, product)\n",
    "    \n",
    "    if os.path.isdir(product_folder):\n",
    "        # Loop through each CSV file in the product folder\n",
    "        for file_name in os.listdir(product_folder):\n",
    "            if file_name.endswith('.CSV'):\n",
    "                file_path = os.path.join(product_folder, file_name)\n",
    "                \n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Check if 'Bid', 'Ask', and 'Spread' columns exist\n",
    "                if 'Bid' in df.columns and 'Ask' in df.columns and 'Spread' in df.columns:\n",
    "                    df['Spread_Calculated'] = df['Ask'] - df['Bid']\n",
    "                    \n",
    "                    # Use the first row's ratio of Spread_Calculated to Spread\n",
    "                    first_ratio = df.loc[0, 'Spread'] / df.loc[0, 'Spread_Calculated']\n",
    "                    \n",
    "                    # Use the round_decimal_dynamic function to round the ratio, avoiding 0.00\n",
    "                    rounded_ratio = round_decimal_dynamic(first_ratio)\n",
    "                    \n",
    "                    # Store this rounded ratio for the product\n",
    "                    spread_ratios[product] = rounded_ratio\n",
    "                    print(f\"First ratio for {product} in StoneX (rounded): {rounded_ratio}\")\n",
    "                    break  # Exit after the first file and first row\n",
    "                else:\n",
    "                    print(f\"File {file_name} in {product} does not contain required columns.\")\n",
    "                break  # Stop after processing the first file for each product\n",
    "\n",
    "# Apply the extracted ratio to other brand folders\n",
    "for brand_folder in os.listdir(base_path):\n",
    "    if brand_folder == 'StoneX':  # Skip StoneX as it has been processed\n",
    "        continue\n",
    "\n",
    "    brand_folder_path = os.path.join(base_path, brand_folder)\n",
    "\n",
    "    # Check if the path is a directory (brand folder)\n",
    "    if os.path.isdir(brand_folder_path):\n",
    "        # Process each product folder inside the brand folder\n",
    "        for product in products:\n",
    "            product_folder = os.path.join(brand_folder_path, product)\n",
    "\n",
    "            if os.path.isdir(product_folder):\n",
    "                # Loop through each CSV file in the product folder\n",
    "                for file_name in os.listdir(product_folder):\n",
    "                    if file_name.endswith('.CSV'):\n",
    "                        file_path = os.path.join(product_folder, file_name)\n",
    "                        \n",
    "                        # Read the CSV file into a DataFrame\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        \n",
    "                        # Check if 'Bid', 'Ask', and 'Spread' columns exist\n",
    "                        if 'Bid' in df.columns and 'Ask' in df.columns and 'Spread' in df.columns:\n",
    "                            # Use the ratio from StoneX to calculate new Spread_Calculated\n",
    "                            if product in spread_ratios:\n",
    "                                df['Spread'] = (df['Ask'] - df['Bid']) * float(spread_ratios[product])\n",
    "                        else:\n",
    "                            print(f\"File {file_name} in {product} does not contain required columns.\")\n",
    "                        \n",
    "                        # Overwrite the original CSV file with the updated DataFrame\n",
    "                        df.to_csv(file_path, index=False)\n",
    "\n",
    "        # Print a message after processing all files in the brand folder\n",
    "        print(f\"Processed all files in brand folder: {brand_folder}\")\n",
    "print(f\"Processed all files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61602893-c2a5-4c8a-9553-bfba3570bd6b",
   "metadata": {},
   "source": [
    "## Get Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1b10a9-d958-4232-95b0-a05b01081998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract date from file name (format: MMDDYYYY)\n",
    "def extract_date_from_filename(filename):\n",
    "    date_str = filename.split('.')[0]  # Extract '05192024' from '05192024.CSV'\n",
    "    return pd.to_datetime(date_str, format='%m%d%Y')\n",
    "\n",
    "# Function to convert the 'Time' column into proper datetime format, including five-digit milliseconds\n",
    "def parse_time_with_five_milliseconds(time_str):\n",
    "    try:\n",
    "        # Split into time and millisecond parts\n",
    "        time_parts = time_str.split(' ')\n",
    "        time = time_parts[0]  # e.g. '20:39:27'\n",
    "        milliseconds = time_parts[1] if len(time_parts) > 1 else '00000'  # Handle missing milliseconds\n",
    "        \n",
    "        # Normalize the milliseconds to always be 5 digits\n",
    "        milliseconds = milliseconds.ljust(5, '0')[:5]  # Pad or truncate to 5 digits\n",
    "\n",
    "        # Combine time and milliseconds into a full time with milliseconds\n",
    "        full_time = f\"{time}.{milliseconds}\"\n",
    "        return full_time\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing time string: {time_str} - {e}\")\n",
    "        return time_str  # Return original in case of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "033c696e-7b29-4f7a-abcc-4dda504df216",
   "metadata": {},
   "outputs": [],
   "source": [
    "stonex_data = {}\n",
    "brand_folder = 'StoneX'  \n",
    "brand_folder_path = os.path.join(base_path, brand_folder)\n",
    "\n",
    "for product in products:\n",
    "    product_folder = os.path.join(brand_folder_path, product)\n",
    "    \n",
    "    if os.path.isdir(product_folder):\n",
    "        # Loop through each CSV file in the product folder\n",
    "        for file_name in os.listdir(product_folder):\n",
    "            if file_name.endswith('.CSV'):\n",
    "                file_path = os.path.join(product_folder, file_name)\n",
    "                \n",
    "                # Extract date from the file name\n",
    "                file_date = extract_date_from_filename(file_name)\n",
    "\n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Ensure necessary columns exist\n",
    "                if 'Time' in df.columns and 'Bid' in df.columns and 'Ask' in df.columns:\n",
    "                    # Convert 'Time' column with five-digit milliseconds\n",
    "                    df['Time'] = df['Time'].apply(parse_time_with_five_milliseconds)\n",
    "\n",
    "                    # Combine the extracted date with the 'Time' column to create 'Timestamp'\n",
    "                    df['Timestamp'] = pd.to_datetime(file_date.strftime('%Y-%m-%d') + ' ' + df['Time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                    df = df[['Timestamp', 'Bid', 'Ask', 'Spread']]\n",
    "                                        \n",
    "                    # Group by hour for StoneX and calculate hourly average\n",
    "                    hourly_avg = df.resample('h', on='Timestamp').mean().reset_index()\n",
    "\n",
    "                    # Calculate the count of records in each hour\n",
    "                    hourly_count = df.resample('h', on='Timestamp').size().reset_index(name='DataCount')\n",
    "\n",
    "                    # Merge the mean and count DataFrames\n",
    "                    hourly_avg = pd.merge(hourly_avg, hourly_count, on='Timestamp')\n",
    "                    hourly_avg['Product'] = product\n",
    "                    hourly_avg['Brand'] = brand_folder\n",
    "                    #print(hourly_avg)\n",
    "                    \n",
    "                    # Store the results in stonex_data            \n",
    "                    if product not in stonex_data:\n",
    "                        stonex_data[product] = pd.DataFrame()  # Initialize if not exist\n",
    "                    \n",
    "                    # Append the data to stonex_data\n",
    "                    stonex_data[product] = pd.concat([stonex_data[product], hourly_avg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0534f5c1-0ccb-4aaf-96bc-d66c92467b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 20240527_test/20240527\\stonex_data_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine all product data into a single DataFrame\n",
    "all_data = pd.concat(stonex_data.values(), ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "output_csv_path = os.path.join(base_path, 'stonex_data_combined.csv')\n",
    "all_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Data has been saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7391d083-6128-4152-a7d5-23f4f7ed2def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other brands data has been saved to 20240527_test/20240527\\other_brands_data_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store data for each brand\n",
    "other_brands_data = {}\n",
    "\n",
    "# Loop through all brands in the base_path directory\n",
    "for brand_folder in os.listdir(base_path):\n",
    "    brand_folder_path = os.path.join(base_path, brand_folder)\n",
    "    \n",
    "    # Skip the 'StoneX' brand (since its data has already been processed)\n",
    "    if brand_folder == 'StoneX':\n",
    "        continue\n",
    "\n",
    "    # Check if the current brand folder is a directory\n",
    "    if os.path.isdir(brand_folder_path):\n",
    "        \n",
    "        for product in products:\n",
    "            product_folder = os.path.join(brand_folder_path, product)\n",
    "            \n",
    "            if os.path.isdir(product_folder):\n",
    "                # Loop through each CSV file in the product folder\n",
    "                for file_name in os.listdir(product_folder):\n",
    "                    if file_name.endswith('.CSV'):\n",
    "                        file_path = os.path.join(product_folder, file_name)\n",
    "                        \n",
    "                        # Extract date from the file name\n",
    "                        file_date = extract_date_from_filename(file_name)\n",
    "\n",
    "                        # Read the CSV file into a DataFrame\n",
    "                        df = pd.read_csv(file_path)\n",
    "\n",
    "                        # Ensure necessary columns exist\n",
    "                        if 'Time' in df.columns and 'Bid' in df.columns and 'Ask' in df.columns:\n",
    "                            # Convert 'Time' column with five-digit milliseconds\n",
    "                            df['Time'] = df['Time'].apply(parse_time_with_five_milliseconds)\n",
    "\n",
    "                            # Combine the extracted date with the 'Time' column to create 'Timestamp'\n",
    "                            df['Timestamp'] = pd.to_datetime(file_date.strftime('%Y-%m-%d') + ' ' + df['Time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                            df = df[['Timestamp', 'Bid', 'Ask', 'Spread']]\n",
    "                                                \n",
    "                            # Group by hour and calculate hourly average\n",
    "                            hourly_avg = df.resample('h', on='Timestamp').mean().reset_index()\n",
    "\n",
    "                            # Calculate the count of records in each hour\n",
    "                            hourly_count = df.resample('h', on='Timestamp').size().reset_index(name='DataCount')\n",
    "\n",
    "                            # Merge the mean and count DataFrames\n",
    "                            hourly_avg = pd.merge(hourly_avg, hourly_count, on='Timestamp')\n",
    "                            hourly_avg['Product'] = product\n",
    "                            hourly_avg['Brand'] = brand_folder\n",
    "                            \n",
    "                            # Store the results in other_brands_data            \n",
    "                            if brand_folder not in other_brands_data:\n",
    "                                other_brands_data[brand_folder] = pd.DataFrame()  # Initialize if not exist\n",
    "                            \n",
    "                            # Append the data to other_brands_data\n",
    "                            other_brands_data[brand_folder] = pd.concat([other_brands_data[brand_folder], hourly_avg], ignore_index=True)\n",
    "\n",
    "# Combine all brand data into a single DataFrame\n",
    "all_other_brands_data = pd.concat(other_brands_data.values(), ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "output_csv_path = os.path.join(base_path, 'other_brands_data_combined.csv')\n",
    "all_other_brands_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Other brands data has been saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a8bd2cd-9c05-4ef5-b3eb-b8889cec1e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other brands data with Spread_Diff has been saved to 20240527_test/20240527\\other_brands_data_with_spread_diff.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store data for each brand\n",
    "other_brands_data = {}\n",
    "\n",
    "# Read the StoneX data into a DataFrame\n",
    "stonex_combined_data = pd.concat(stonex_data.values(), ignore_index=True)\n",
    "\n",
    "# Loop through all brands in the base_path directory\n",
    "for brand_folder in os.listdir(base_path):\n",
    "    brand_folder_path = os.path.join(base_path, brand_folder)\n",
    "    \n",
    "    # Skip the 'StoneX' brand (since its data has already been processed)\n",
    "    if brand_folder == 'StoneX':\n",
    "        continue\n",
    "\n",
    "    # Check if the current brand folder is a directory\n",
    "    if os.path.isdir(brand_folder_path):\n",
    "        \n",
    "        for product in products:\n",
    "            product_folder = os.path.join(brand_folder_path, product)\n",
    "            \n",
    "            if os.path.isdir(product_folder):\n",
    "                # Loop through each CSV file in the product folder\n",
    "                for file_name in os.listdir(product_folder):\n",
    "                    if file_name.endswith('.CSV'):\n",
    "                        file_path = os.path.join(product_folder, file_name)\n",
    "                        \n",
    "                        # Extract date from the file name\n",
    "                        file_date = extract_date_from_filename(file_name)\n",
    "\n",
    "                        # Read the CSV file into a DataFrame\n",
    "                        df = pd.read_csv(file_path)\n",
    "\n",
    "                        # Ensure necessary columns exist\n",
    "                        if 'Time' in df.columns and 'Bid' in df.columns and 'Ask' in df.columns:\n",
    "                            # Convert 'Time' column with five-digit milliseconds\n",
    "                            df['Time'] = df['Time'].apply(parse_time_with_five_milliseconds)\n",
    "\n",
    "                            # Combine the extracted date with the 'Time' column to create 'Timestamp'\n",
    "                            df['Timestamp'] = pd.to_datetime(file_date.strftime('%Y-%m-%d') + ' ' + df['Time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                            df = df[['Timestamp', 'Bid', 'Ask', 'Spread']]\n",
    "                                                \n",
    "                            # Group by hour and calculate hourly average\n",
    "                            hourly_avg = df.resample('h', on='Timestamp').mean().reset_index()\n",
    "\n",
    "                            # Calculate the count of records in each hour\n",
    "                            hourly_count = df.resample('h', on='Timestamp').size().reset_index(name='DataCount')\n",
    "\n",
    "                            # Merge the mean and count DataFrames\n",
    "                            hourly_avg = pd.merge(hourly_avg, hourly_count, on='Timestamp')\n",
    "                            hourly_avg['Product'] = product\n",
    "                            hourly_avg['Brand'] = brand_folder\n",
    "                            \n",
    "                            # Store the results in other_brands_data            \n",
    "                            if brand_folder not in other_brands_data:\n",
    "                                other_brands_data[brand_folder] = pd.DataFrame()  # Initialize if not exist\n",
    "                            \n",
    "                            # Append the data to other_brands_data\n",
    "                            other_brands_data[brand_folder] = pd.concat([other_brands_data[brand_folder], hourly_avg], ignore_index=True)\n",
    "\n",
    "# Combine all other brand data into a single DataFrame\n",
    "all_other_brands_data = pd.concat(other_brands_data.values(), ignore_index=True)\n",
    "\n",
    "# Merge the StoneX data with the other brands data on 'Timestamp' and 'Product' to calculate Spread_Diff\n",
    "combined_data_with_diff = pd.merge(all_other_brands_data, stonex_combined_data[['Timestamp', 'Product', 'Spread']], on=['Timestamp', 'Product'], how='left', suffixes=('', '_StoneX'))\n",
    "\n",
    "# Calculate Spread_Diff as the difference between the other brand's Spread and StoneX's Spread for the same product\n",
    "combined_data_with_diff['Spread_Diff'] = combined_data_with_diff['Spread'] - combined_data_with_diff['Spread_StoneX']\n",
    "\n",
    "# Save the combined DataFrame with Spread_Diff to a CSV file\n",
    "output_csv_path = os.path.join(base_path, 'other_brands_data_with_spread_diff.csv')\n",
    "combined_data_with_diff.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Other brands data with Spread_Diff has been saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2223ddb1-37d9-4f11-88bc-c5ec9706c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined and filtered CSV file saved at 20240527_test\\20240527\\final_combined_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the two CSV files\n",
    "stonex_file = r'20240527_test\\20240527\\stonex_data_combined.csv'\n",
    "other_brands_file = r'20240527_test\\20240527\\other_brands_data_with_spread_diff.csv'\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "stonex_df = pd.read_csv(stonex_file)\n",
    "other_brands_df = pd.read_csv(other_brands_file)\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([stonex_df, other_brands_df], ignore_index=True)\n",
    "\n",
    "# Drop rows where DataCount is less than 10\n",
    "filtered_combined_df = combined_df[combined_df['DataCount'] >= 5]\n",
    "\n",
    "# Define the output path for the final combined CSV\n",
    "output_combined_file = r'20240527_test\\20240527\\final_combined_filtered.csv'\n",
    "\n",
    "# Save the filtered combined data to a new CSV file\n",
    "filtered_combined_df.to_csv(output_combined_file, index=False)\n",
    "\n",
    "print(f\"Final combined and filtered CSV file saved at {output_combined_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
